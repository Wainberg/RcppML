<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Getting Started with NMF • RcppML</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/simplex/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet">
<meta property="og:title" content="Getting Started with NMF">
<meta property="og:description" content="RcppML">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">RcppML</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.5.2</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/getting_started.html">Getting Started with NMF</a>
    </li>
    <li>
      <a href="../articles/robust_nmf.html">Robust NMF with random initializations</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/zdebruine/RcppML/">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="getting_started_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Getting Started with NMF</h1>
                        <h4 class="author">Zach DeBruine</h4>
            
            <h4 class="date">2021-10-22</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/zdebruine/RcppML/blob/master/vignettes/getting_started.Rmd"><code>vignettes/getting_started.Rmd</code></a></small>
      <div class="hidden name"><code>getting_started.Rmd</code></div>

    </div>

    
    
<p>This vignette demonstrates basic usage of the <code><a href="../reference/nmf.html">RcppML::nmf</a></code> function and visualization of the results.</p>
<div id="install-rcppml" class="section level2">
<h2 class="hasAnchor">
<a href="#install-rcppml" class="anchor"></a>Install RcppML</h2>
<p>Install the RcppML R package from CRAN or the development version from GitHub.</p>
<p>Also install the accompanying Machine Learning datasets (MLdata) package:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html">install.packages</a></span><span class="op">(</span><span class="st">'RcppML'</span><span class="op">)</span>                     <span class="co"># install CRAN version</span>
<span class="co"># devtools::install_github("zdebruine/RcppML") # compile dev version</span>
<span class="fu">devtools</span><span class="fu">::</span><span class="fu"><a href="https://devtools.r-lib.org//reference/remote-reexports.html">install_github</a></span><span class="op">(</span><span class="st">"zdebruine/MLdata"</span><span class="op">)</span></code></pre></div>
</div>
<div id="what-is-nmf" class="section level2">
<h2 class="hasAnchor">
<a href="#what-is-nmf" class="anchor"></a>What is NMF?</h2>
<p>Non-negative Matrix Factorization (NMF) finds additive signals in non-negative data in terms of the features and samples associated with those signals.</p>
<p>NMF gives an approximation of an input matrix as the cross-product of two low-rank submatrices:</p>
<p><span class="math display">\[A = wdh\]</span></p>
<p>Here, <span class="math inline">\(A\)</span> is the input matrix, <span class="math inline">\(w\)</span> is a tall matrix of features in rows and factors in columns, and <span class="math inline">\(h\)</span> is a wide matrix of factors in rows and samples in columns.</p>
<p><code><a href="../reference/nmf.html">RcppML::nmf</a></code> introduces one more important component into this system, a scaling diagonal, <span class="math inline">\(d\)</span>. This scaling diagonal provides:</p>
<ul>
<li>consistent factor scalings throughout model fitting</li>
<li>robustness across random restarts</li>
<li>symmetry in factorization of symmetric matrices</li>
<li>a means for convex L1 regularization</li>
</ul>
</div>
<div id="running-nmf" class="section level2">
<h2 class="hasAnchor">
<a href="#running-nmf" class="anchor"></a>Running NMF</h2>
<p>Run NMF on the <code>iris</code> dataset. We need to specify a rank (<code>k</code>) for the factorization, and will also specify the <code>seed</code> for random initialization for reproducibility:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/zdebruine/RcppML">RcppML</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://Matrix.R-forge.R-project.org/">Matrix</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/zdebruine/MLdata">MLdata</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://wilkelab.org/cowplot/">cowplot</a></span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">iris</span><span class="op">)</span>
<span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nmf.html">nmf</a></span><span class="op">(</span><span class="va">iris</span><span class="op">[</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span>, k <span class="op">=</span> <span class="fl">3</span>, seed <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">model</span>
<span class="co">#&gt; 150 x 4 x 3 factor model of class "nmf"</span>
<span class="co">#&gt; @ w</span>
<span class="co">#&gt;              nmf1         nmf2         nmf3</span>
<span class="co">#&gt; [1,] 0.0014403134 0.0002357974 0.0147753897</span>
<span class="co">#&gt; [2,] 0.0024259960            . 0.0129176731</span>
<span class="co">#&gt; [3,] 0.0014543773 0.0001794741 0.0134988417</span>
<span class="co">#&gt; [4,] 0.0019489186 0.0005632185 0.0124668937</span>
<span class="co">#&gt; [5,] 0.0001151302 0.0015972125 0.0148072020</span>
<span class="co">#&gt; [6,]            . 0.0030264275 0.0151420941</span>
<span class="co">#&gt; [7,]            . 0.0022133280 0.0132919365</span>
<span class="co">#&gt; ...suppressing 143 rows</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; @ d</span>
<span class="co">#&gt; 747.8924  726.0631  605.7889  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; @ h</span>
<span class="co">#&gt;      Sepal.Length Sepal.Width Petal.Length Petal.Width</span>
<span class="co">#&gt; nmf1  0.426857790 0.123598613  0.355488027 0.094055570</span>
<span class="co">#&gt; nmf2  0.340537544 0.193888276  0.320817305 0.144756875</span>
<span class="co">#&gt; nmf3  0.511768434 0.372576543  0.107677454 0.007977569</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; @ misc</span>
<span class="co">#&gt; List of 4</span>
<span class="co">#&gt;  $ tol    : num 9.76e-05</span>
<span class="co">#&gt;  $ iter   : num 14</span>
<span class="co">#&gt;  $ runtime: 'difftime' num 0.00800418853759766</span>
<span class="co">#&gt;   ..- attr(*, "units")= chr "secs"</span>
<span class="co">#&gt;  $ w_init : num [1:3, 1:150] 0.266 0.372 0.573 0.908 0.202 ...</span></code></pre></div>
</div>
<div id="visualizing-nmf-models" class="section level2">
<h2 class="hasAnchor">
<a href="#visualizing-nmf-models" class="anchor"></a>Visualizing NMF Models</h2>
<p>The result of <code><a href="../reference/nmf.html">RcppML::nmf</a></code> is an S3 object of class <code>nmf</code>. The <code>nmf</code> class has many useful methods:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/methods.html">methods</a></span><span class="op">(</span>class <span class="op">=</span> <span class="st">"nmf"</span><span class="op">)</span>
<span class="co">#&gt;  [1] $        [        align    biplot   coerce   dim      dimnames evaluate</span>
<span class="co">#&gt;  [9] head     predict  prod     show     sort     sparsity subset   summary </span>
<span class="co">#&gt; [17] t       </span>
<span class="co">#&gt; see '?methods' for accessing help and source code</span></code></pre></div>
<p>One of these useful methods is <code>summary</code> (which in turn has a <code>plot</code> method):</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">species_stats</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model</span>, group_by <span class="op">=</span> <span class="va">iris</span><span class="op">$</span><span class="va">Species</span><span class="op">)</span>
<span class="va">species_stats</span>
<span class="co">#&gt;        group factor       stat</span>
<span class="co">#&gt; 1     setosa   nmf1 0.06364741</span>
<span class="co">#&gt; 2 versicolor   nmf1 0.46947182</span>
<span class="co">#&gt; 3  virginica   nmf1 0.46688076</span>
<span class="co">#&gt; 4     setosa   nmf2 0.04650387</span>
<span class="co">#&gt; 5 versicolor   nmf2 0.31381639</span>
<span class="co">#&gt; 6  virginica   nmf2 0.63967974</span>
<span class="co">#&gt; 7     setosa   nmf3 0.70431244</span>
<span class="co">#&gt; 8 versicolor   nmf3 0.22449607</span>
<span class="co">#&gt; 9  virginica   nmf3 0.07119149</span></code></pre></div>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">species_stats</span>, stat <span class="op">=</span> <span class="st">"sum"</span><span class="op">)</span></code></pre></div>
<p><img src="getting_started_files/figure-html/unnamed-chunk-6-1.png" width="288"></p>
<p>Notice how NMF factors capture variable information among iris species.</p>
<p>The <code>biplot</code> method for NMF (see <code>?biplot.nmf</code> for details) can compare the weights of different features or samples in two factors:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/biplot.html">biplot</a></span><span class="op">(</span><span class="va">model</span>, factors <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span>, group_by <span class="op">=</span> <span class="va">iris</span><span class="op">$</span><span class="va">Species</span><span class="op">)</span></code></pre></div>
<p><img src="getting_started_files/figure-html/unnamed-chunk-7-1.png" width="384"></p>
</div>
<div id="random-restarts" class="section level2">
<h2 class="hasAnchor">
<a href="#random-restarts" class="anchor"></a>Random Restarts</h2>
<p>NMF is randomly initialized, thus results may be slightly different every time. To run NMF many times, set multiple seeds, and the best model will be returned.</p>
<p>Here we run 10 factorizations at a higher tolerance, and the best model is returned:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">model2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nmf.html">nmf</a></span><span class="op">(</span><span class="va">iris</span><span class="op">[</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span>, k <span class="op">=</span> <span class="fl">3</span>, seed <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">10</span>, tol <span class="op">=</span> <span class="fl">1e-5</span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># MSE of model from single random initialization</span>
<span class="fu">evaluate</span><span class="op">(</span><span class="va">model</span>, <span class="va">iris</span><span class="op">[</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span><span class="op">)</span>
<span class="co">#&gt; [1] 0.007247329</span>

<span class="co"># MSE of best model among 10 random restarts</span>
<span class="fu">evaluate</span><span class="op">(</span><span class="va">model2</span>, <span class="va">iris</span><span class="op">[</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span><span class="op">)</span>
<span class="co">#&gt; [1] 0.006100573</span></code></pre></div>
<p>The second model is slightly better.</p>
</div>
<div id="l1-regularization" class="section level2">
<h2 class="hasAnchor">
<a href="#l1-regularization" class="anchor"></a>L1 Regularization</h2>
<p>Sparse factors contain only a few non-zero values and make it easy to identify features or samples that are important.</p>
<p>L1/LASSO regularization is the best method for introducing sparsity into a linear model.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">movielens</span><span class="op">)</span>
<span class="va">ratings</span> <span class="op">&lt;-</span> <span class="va">movielens</span><span class="op">$</span><span class="va">ratings</span>
<span class="va">model_L1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nmf.html">nmf</a></span><span class="op">(</span><span class="va">ratings</span>, k <span class="op">=</span> <span class="fl">7</span>, L1 <span class="op">=</span> <span class="fl">0.1</span>, seed <span class="op">=</span> <span class="fl">123</span>, mask_zeros <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">sparsity</span><span class="op">(</span><span class="va">model_L1</span><span class="op">)</span>
<span class="co">#&gt;    factor  sparsity model</span>
<span class="co">#&gt; 1    nmf1 0.6224463     w</span>
<span class="co">#&gt; 2    nmf2 0.8774244     w</span>
<span class="co">#&gt; 3    nmf3 0.6351177     w</span>
<span class="co">#&gt; 4    nmf4 0.5958107     w</span>
<span class="co">#&gt; 5    nmf5 0.8988880     w</span>
<span class="co">#&gt; 6    nmf6 0.2924748     w</span>
<span class="co">#&gt; 7    nmf7 0.4641841     w</span>
<span class="co">#&gt; 8    nmf1 0.6754098     h</span>
<span class="co">#&gt; 9    nmf2 0.2803279     h</span>
<span class="co">#&gt; 10   nmf3 0.6508197     h</span>
<span class="co">#&gt; 11   nmf4 0.7213115     h</span>
<span class="co">#&gt; 12   nmf5 0.4295082     h</span>
<span class="co">#&gt; 13   nmf6 0.9229508     h</span>
<span class="co">#&gt; 14   nmf7 0.9393443     h</span></code></pre></div>
<p>The <code>sparsity</code> S3 method for class <code>nmf</code> makes it easy to compute the sparsity of factors, as done above.</p>
<p>Note that <code>mask_zeros = TRUE</code> in the example above. This is because zero-valued ratings are missing, and thus should not be considered during factorization.</p>
<p>In the above example, we regularized both <span class="math inline">\(w\)</span> and <span class="math inline">\(h\)</span>, however each model can also be regularized separately:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">model_no_L1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nmf.html">nmf</a></span><span class="op">(</span><span class="va">ratings</span>, k <span class="op">=</span> <span class="fl">7</span>, L1 <span class="op">=</span> <span class="fl">0</span>, seed <span class="op">=</span> <span class="fl">123</span>, mask_zeros <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="va">model_L1_h</span> <span class="op">&lt;-</span>  <span class="fu"><a href="../reference/nmf.html">nmf</a></span><span class="op">(</span><span class="va">ratings</span>, k <span class="op">=</span> <span class="fl">7</span>, L1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.1</span><span class="op">)</span>, seed <span class="op">=</span> <span class="fl">123</span>, mask_zeros <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="va">model_L1_w</span> <span class="op">&lt;-</span>  <span class="fu"><a href="../reference/nmf.html">nmf</a></span><span class="op">(</span><span class="va">ratings</span>, k <span class="op">=</span> <span class="fl">7</span>, L1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0</span><span class="op">)</span>, seed <span class="op">=</span> <span class="fl">123</span>, mask_zeros <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>

<span class="co"># summarize sparsity of all models in a data.frame</span>
<span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="fu">sparsity</span><span class="op">(</span><span class="va">model_no_L1</span><span class="op">)</span>, <span class="fu">sparsity</span><span class="op">(</span><span class="va">model_L1_h</span><span class="op">)</span>, <span class="fu">sparsity</span><span class="op">(</span><span class="va">model_L1_w</span><span class="op">)</span>, <span class="fu">sparsity</span><span class="op">(</span><span class="va">model_L1</span><span class="op">)</span><span class="op">)</span>
<span class="va">df</span><span class="op">$</span><span class="va">side</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">"none"</span>, <span class="fl">14</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">"h only"</span>, <span class="fl">14</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">"w only"</span>, <span class="fl">14</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="st">"both"</span>, <span class="fl">14</span><span class="op">)</span><span class="op">)</span>
<span class="va">df</span><span class="op">$</span><span class="va">side</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">side</span>, levels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/unique.html">unique</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">side</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">df</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">side</span>, y <span class="op">=</span> <span class="va">sparsity</span>, color <span class="op">=</span> <span class="va">model</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_boxplot.html">geom_boxplot</a></span><span class="op">(</span>outlier.shape <span class="op">=</span> <span class="cn">NA</span>, width <span class="op">=</span> <span class="fl">0.6</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>position <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/position_jitterdodge.html">position_jitterdodge</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Regularized side of model"</span>, y <span class="op">=</span> <span class="st">"sparsity of model factors"</span><span class="op">)</span></code></pre></div>
<p><img src="getting_started_files/figure-html/unnamed-chunk-13-1.png" width="384"></p>
<p>Note how each side of the model is regularized independently.</p>
<p>L1 regularization does not significantly affect model loss:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># L1 = 0</span>
<span class="fu">evaluate</span><span class="op">(</span><span class="va">model_no_L1</span>, <span class="va">movielens</span><span class="op">$</span><span class="va">ratings</span>, mask <span class="op">=</span> <span class="st">"zeros"</span><span class="op">)</span>
<span class="co">#&gt; [1] 6.868603</span>

<span class="co"># L1 = 0.1</span>
<span class="fu">evaluate</span><span class="op">(</span><span class="va">model_L1</span>, <span class="va">movielens</span><span class="op">$</span><span class="va">ratings</span>, mask <span class="op">=</span> <span class="st">"zeros"</span><span class="op">)</span>
<span class="co">#&gt; [1] 7.41899</span></code></pre></div>
<p>L1 regularization also does not significantly affect model information at low penalties. Here we measure the cost of bipartite matching between two models on a cosine distance matrix for <code>L1 = 0</code>, <code>L1 = 0.01</code>, and <code>L1 = 0.1</code>:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">model_low_L1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nmf.html">nmf</a></span><span class="op">(</span><span class="va">movielens</span><span class="op">$</span><span class="va">ratings</span>, k <span class="op">=</span> <span class="fl">5</span>, L1 <span class="op">=</span> <span class="fl">0.01</span>, seed <span class="op">=</span> <span class="fl">123</span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># cost of bipartite matching: L1 = 0 vs. L1 = 0.01</span>
<span class="fu"><a href="../reference/bipartiteMatch.html">bipartiteMatch</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="../reference/cosine.html">cosine</a></span><span class="op">(</span><span class="va">model_no_L1</span><span class="op">$</span><span class="va">w</span>, <span class="va">model_low_L1</span><span class="op">$</span><span class="va">w</span><span class="op">)</span><span class="op">)</span><span class="op">$</span><span class="va">cost</span> <span class="op">/</span> <span class="fl">10</span>
<span class="co">#&gt; [1] 0.03932585</span>

<span class="co"># cost of bipartite matching: L1 = 0 vs. L1 = 0.1</span>
<span class="fu"><a href="../reference/bipartiteMatch.html">bipartiteMatch</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="../reference/cosine.html">cosine</a></span><span class="op">(</span><span class="va">model_no_L1</span><span class="op">$</span><span class="va">w</span>, <span class="va">model_L1</span><span class="op">$</span><span class="va">w</span><span class="op">)</span><span class="op">)</span><span class="op">$</span><span class="va">cost</span> <span class="op">/</span> <span class="fl">10</span>
<span class="co">#&gt; [1] 0.07304686</span></code></pre></div>
<p>See <code><a href="../reference/cosine.html">?RcppML::cosine</a></code> for details on very fast computation of cosine similarity.</p>
<p>In the above code, we computed cosine distance by subtracting cosine similarity from 1, matched on this cost matrix, and divided by 10 to find the mean cosine distance between matched factors. In both cases, factors correspond well.</p>
<p>Thus, regularized <code><a href="../reference/nmf.html">RcppML::nmf</a></code> increases factor sparsity without significantly affecting the loss or information content of the model.</p>
</div>
<div id="predictionrecommendation-with-nmf" class="section level2">
<h2 class="hasAnchor">
<a href="#predictionrecommendation-with-nmf" class="anchor"></a>Prediction/Recommendation with NMF</h2>
<p>NMF models learned on some samples can be projected to other samples, a common routine in recommender systems or transfer learning.</p>
<p>For instance, we may train a model on movie ratings from many users in the <code>movielens</code> dataset (training users) and predict ratings for the remaining users (test users).</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">train_users</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">ratings</span><span class="op">)</span>, <span class="fl">500</span><span class="op">)</span>

<span class="co"># remove movies with fewer than 5 ratings in the training set</span>
<span class="va">movies</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/colSums.html">rowSums</a></span><span class="op">(</span><span class="va">ratings</span><span class="op">[</span>, <span class="va">train_users</span><span class="op">]</span><span class="op">)</span> <span class="op">&gt;</span> <span class="fl">5</span><span class="op">)</span>
<span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nmf.html">nmf</a></span><span class="op">(</span><span class="va">ratings</span><span class="op">[</span><span class="va">movies</span>, <span class="va">train_users</span><span class="op">]</span>, k <span class="op">=</span> <span class="fl">10</span>, mask_zeros <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="va">predictions</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">model</span>, <span class="va">ratings</span><span class="op">[</span><span class="va">movies</span>, <span class="op">-</span><span class="va">train_users</span><span class="op">]</span><span class="op">)</span></code></pre></div>
<p>Now we can assess the ability of our model to predict movie ratings by users in the test set. Because we trained the model with <code>mask_zeros = TRUE</code>, we also need to do the same when calculating mean squared error:</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">evaluate</span><span class="op">(</span><span class="fu">new</span><span class="op">(</span><span class="st">"nmf"</span>, w <span class="op">=</span> <span class="va">model</span><span class="op">@</span><span class="va">w</span>, d <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">10</span><span class="op">)</span>, h <span class="op">=</span> <span class="va">predictions</span><span class="op">)</span>, <span class="va">ratings</span><span class="op">[</span><span class="va">movies</span>, <span class="op">-</span><span class="va">train_users</span><span class="op">]</span>, mask <span class="op">=</span> <span class="st">"zeros"</span><span class="op">)</span>
<span class="co">#&gt; [1] 6.683479</span></code></pre></div>
</div>
<div id="cross-validation-for-rank-determination" class="section level2">
<h2 class="hasAnchor">
<a href="#cross-validation-for-rank-determination" class="anchor"></a>Cross-validation for rank determination</h2>
<p>Cross-validation can assist in finding a reasonable factorization rank. However, like many dimensional reductions, a single “best” rank rarely exists.</p>
<p>We will demonstrate cross-validation using two simulated datasets generated with <code>simulateNMF</code>:</p>
<ol style="list-style-type: decimal">
<li>
<code>data_clean</code> will have no noise or signal dropout</li>
<li>
<code>data_dirty</code> contains the same signal as <code>data_clean</code>, but with a bit of noise and a lot of dropout</li>
</ol>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">data_clean</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/simulateNMF.html">simulateNMF</a></span><span class="op">(</span>nrow <span class="op">=</span> <span class="fl">100</span>, ncol <span class="op">=</span> <span class="fl">100</span>, k <span class="op">=</span> <span class="fl">5</span>, noise <span class="op">=</span> <span class="fl">0</span>, dropout <span class="op">=</span> <span class="fl">0</span>, seed <span class="op">=</span> <span class="fl">123</span><span class="op">)</span>
<span class="va">data_dirty</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/simulateNMF.html">simulateNMF</a></span><span class="op">(</span>nrow <span class="op">=</span> <span class="fl">100</span>, ncol <span class="op">=</span> <span class="fl">100</span>, k <span class="op">=</span> <span class="fl">5</span>, noise <span class="op">=</span> <span class="fl">0.25</span>, dropout <span class="op">=</span> <span class="fl">0.4</span>, seed <span class="op">=</span> <span class="fl">123</span><span class="op">)</span></code></pre></div>
<p>Notice how <code>data_clean</code> contains only 5 non-zero singular values, while <code>data_dirty</code> does not:</p>
<p><img src="getting_started_files/figure-html/unnamed-chunk-20-1.png" width="288"></p>
<p>We can use <code><a href="../reference/crossValidate.html">RcppML::crossValidate</a></code> to determine the rank of each dataset. The default method uses “bi-cross-validation”. See <code><a href="../reference/crossValidate.html">?crossValidate</a></code> for details.</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">cv_clean</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/crossValidate.html">crossValidate</a></span><span class="op">(</span><span class="va">data_clean</span>, k <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">10</span>, seed <span class="op">=</span> <span class="fl">123</span><span class="op">)</span>
<span class="va">cv_dirty</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/crossValidate.html">crossValidate</a></span><span class="op">(</span><span class="va">data_dirty</span>, k <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">10</span>, seed <span class="op">=</span> <span class="fl">123</span><span class="op">)</span>
<span class="fu"><a href="https://wilkelab.org/cowplot/reference/plot_grid.html">plot_grid</a></span><span class="op">(</span>
  <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">cv_clean</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ggtitle</a></span><span class="op">(</span><span class="st">"cross-validation on\nclean dataset"</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_y_continuous</a></span><span class="op">(</span>limits <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span>,
  <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">cv_dirty</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ggtitle</a></span><span class="op">(</span><span class="st">"cross-validation on\ndirty dataset"</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>
<span class="co">#&gt; Warning: Removed 9 rows containing missing values (geom_point).</span>
<span class="co">#&gt; Warning: Removed 2 row(s) containing missing values (geom_path).</span></code></pre></div>
<p><img src="getting_started_files/figure-html/unnamed-chunk-21-1.png" width="576"></p>
<p><code>crossValidate</code> also supports another method which compares robustness of two factorizations on independent sample subsets.</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">cv_clean</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/crossValidate.html">crossValidate</a></span><span class="op">(</span><span class="va">data_clean</span>, k <span class="op">=</span> <span class="fl">2</span><span class="op">:</span><span class="fl">10</span>, method <span class="op">=</span> <span class="st">"robust"</span>, seed <span class="op">=</span> <span class="fl">123</span><span class="op">)</span>
<span class="va">cv_dirty</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/crossValidate.html">crossValidate</a></span><span class="op">(</span><span class="va">data_dirty</span>, k <span class="op">=</span> <span class="fl">2</span><span class="op">:</span><span class="fl">10</span>, method <span class="op">=</span> <span class="st">"robust"</span>, seed <span class="op">=</span> <span class="fl">123</span><span class="op">)</span>
<span class="fu"><a href="https://wilkelab.org/cowplot/reference/plot_grid.html">plot_grid</a></span><span class="op">(</span>
  <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">cv_clean</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ggtitle</a></span><span class="op">(</span><span class="st">"cross-validation on\nclean dataset"</span><span class="op">)</span>,
  <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">cv_dirty</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ggtitle</a></span><span class="op">(</span><span class="st">"cross-validation on\ndirty dataset"</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></code></pre></div>
<p><img src="getting_started_files/figure-html/unnamed-chunk-22-1.png" width="576"></p>
<p>For real datasets, it is important to experiment with all cross-validation methods and to explore multi-resolution analysis or other objectives where appropriate.</p>
<p><code>crossValidate</code> does not support an objective against the mean squared error of imputed missing values because this method is slow, tends to under-estimate the true rank, and does not handle noisy data well.</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Zach DeBruine.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
