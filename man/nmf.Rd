% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/nmf.R
\name{nmf}
\alias{nmf}
\alias{mse.nmf}
\alias{predict.nmf}
\title{Non-negative matrix factorization}
\usage{
nmf(
  data,
  k,
  tol = 1e-04,
  maxit = 100,
  verbose = TRUE,
  L1 = c(0, 0),
  seed = NULL,
  nonneg = TRUE,
  mask_zeros = FALSE,
  ...
)

\method{mse}{nmf}(object, data, mask_zeros = FALSE, ...)

\method{predict}{nmf}(object, newdata, L1 = 0, nonneg = TRUE, mask_zeros = FALSE, ...)
}
\arguments{
\item{data}{input data with the same number of rows as \code{object$w}}

\item{k}{rank}

\item{tol}{stopping criteria based on the correlation distance between \eqn{w} across consecutive iterations. Prefer \code{tol <= 1e-5} for publication runs, \code{1e-5 < tol <= 1e-3} for rapid experimentation.}

\item{maxit}{maximum permitted update iterations}

\item{verbose}{print tolerance after each iteration}

\item{L1}{LASSO penalties in the range (0, 1], array of length two for \code{c(w, h)}}

\item{seed}{random seed for initializing \code{w}, or initial \code{w} matrix. If an array of seeds (or list of \code{w} matrices) is provided, \code{nmf} will be run for each seed and the fitted model with the lowest Mean Squared Error will be returned.}

\item{nonneg}{enforce non-negativity}

\item{mask_zeros}{handle zeros as missing values}

\item{...}{development parameters}

\item{object}{model of class \code{nmf}, generally the result of calling \code{nmf}}

\item{newdata}{matrix of features-by-samples in dense or sparse format, coercible to \code{matrix} or \code{Matrix::dgCMatrix}, must contain the same number of rows as \code{object$w}.}
}
\value{
\code{nmf} returns a list with class "\code{nmf}" containing the following components:
\itemize{
\item w    : feature factor matrix
\item d    : scaling diagonal vector
\item h    : sample factor matrix
\item tol  : tolerance between models at final update
\item iter : number of alternating updates
}
}
\description{
High-performance NMF of the form \eqn{A = wdh} for large dense or sparse matrices, returns an object of class \code{nmf}.
}
\details{
This fast NMF implementation decomposes a matrix \eqn{A} into lower-rank non-negative matrices \eqn{w} and \eqn{h},
with columns of \eqn{w} and rows of \eqn{h} scaled to sum to 1 via multiplication by a diagonal, \eqn{d}: \deqn{A = wdh}

The scaling diagonal ensures convex L1 regularization, consistent factor scalings regardless of random initialization, and model symmetry in factorizations of symmetric matrices.

The factorization model is randomly initialized.  \eqn{w} and \eqn{h} are updated by alternating least squares.

RcppML achieves high performance using the Eigen C++ linear algebra library, OpenMP parallelization, a dedicated Rcpp sparse matrix class, and fast sequential coordinate descent non-negative least squares initialized by Cholesky least squares solutions.

Parallelization is applied with OpenMP using the number of threads set by \code{\link{setRcppMLthreads}}. When \code{k < 3} or \code{setRcppMLthreads(1)}, a backend compiled without OpenMP is used for optimal performance. NMF with \code{mask_zeros = TRUE} is always single-threaded for efficiency.

Sparse optimization is automatically applied if the input matrix \code{A} is a sparse matrix (i.e. \code{Matrix::dgCMatrix}). There are also specialized back-ends for symmetric, rank-1, and rank-2 factorizations.

L1 penalization can be used for increasing the sparsity of factors and assisting interpretability. Penalty values should range from 0 to 1, where 1 gives complete sparsity.
}
\section{Methods}{

The \code{nmf} S3 class has several methods:
\itemize{
\item \code{predict(object, newdata, L1 = 0)}: equivalent to \code{\link{project}}, project the model onto new samples.
\item \code{mse(object, data)}: calculates mean squared error loss of the model, \code{data} must be the same data used to fit the model.
\item \code{prod}: compute the product of the model (multiply it out). Returns a dense matrix
\item \code{summary(object, group_by, stat = "fractional")}: \code{data.frame} giving \code{fractional}, \code{total}, or \code{mean} representation of factors in samples or features grouped by some criteria
\item \code{sparsity(object)}: returns a \code{data.frame} giving sparsity of each factor in \eqn{w} and \eqn{h}
\item \code{match(x, y)}: find an ordering of factors in \code{nmf} model \code{y$w} that best matches those in \code{nmf} model \code{x$w} based on cost of \code{\link{bipartiteMatch}} on a \code{\link{cosine}} similarity matrix.
\item \code{`[`}: subset, reorder, select, or extract factors
\item generics such as \code{dim}, \code{t} (transpose), \code{print}, \code{head}, \code{dimnames}
}
}

\examples{
\dontrun{
library(Matrix)
# basic NMF
model <- nmf(rsparsematrix(1000, 100, 0.1), k = 10)

# compare rank-2 NMF to second left vector in an SVD
data(iris)
A <- as(as.matrix(iris[,1:4]), "dgCMatrix")
nmf_model <- nmf(A, 2, tol = 1e-5)
bipartitioning_vector <- apply(nmf_model$w, 1, diff)
second_left_svd_vector <- base::svd(A, 2)$u[,2]
abs(cor(bipartitioning_vector, second_left_svd_vector))

# compare rank-1 NMF with first singular vector in an SVD
abs(cor(nmf(A, 1)$w[,1], base::svd(A, 2)$u[,1]))

# symmetric NMF
A <- crossprod(rsparsematrix(100, 100, 0.02))
model <- nmf(A, 10, tol = 1e-5, maxit = 1000)
plot(model$w, t(model$h))
# see package vignette for more examples
}
}
\references{
DeBruine, ZJ, Melcher, K, and Triche, TJ. (2021). "High-performance non-negative matrix factorization for large single-cell data." BioRXiv.

Lin, X, and Boutros, PC (2020). "Optimization and expansion of non-negative matrix factorization." BMC Bioinformatics.

Lee, D, and Seung, HS (1999). "Learning the parts of objects by non-negative matrix factorization." Nature.

Franc, VC, Hlavac, VC, Navara, M. (2005). "Sequential Coordinate-Wise Algorithm for the Non-negative Least Squares Problem". Proc. Int'l Conf. Computer Analysis of Images and Patterns. Lecture Notes in Computer Science.
}
\seealso{
\code{\link{predict.nmf}}, \code{\link{mse.nmf}}, \code{\link{nnls}}
}
\author{
Zach DeBruine
}
