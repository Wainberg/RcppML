% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/nmf.R
\name{nmf}
\alias{nmf}
\title{Matrix factorization by alternating least squares}
\usage{
nmf(
  A,
  k,
  nonneg = c(TRUE, TRUE),
  tol = 0.001,
  L1 = c(0, 0),
  seed = NULL,
  maxit = 100,
  threads = 0,
  verbose = TRUE,
  diag = TRUE,
  symmetric = FALSE,
  fast_maxit = 10,
  cd_maxit = 100,
  cd_tol = 1e-08,
  calc_mse = FALSE,
  precision = "double"
)
}
\arguments{
\item{A}{matrix of features x samples, of or coercible to sparse matrix \code{dgCMatrix} format}

\item{k}{rank of factorization}

\item{nonneg}{apply non-negativity constraints to \code{c(w, h)}, specify \code{TRUE} for NMF, \code{c(TRUE, FALSE)} for OSNMF/L or \code{c(FALSE, TRUE)} for OSNMF/R.}

\item{tol}{stopping criterion for alternating least squares iterations, measuring mean correlation distance between \eqn{w} and \eqn{h} in consecutive iterations.}

\item{L1}{L1 ("lasso") regularization to apply to either 'w' or 'h', recommended only to use with diagonalization. Specify array of two for \code{c(w, h)}}

\item{seed}{random seed for initialization of \eqn{w}, uses C++ \code{srand} RNG.}

\item{maxit}{maximum number of alternating least squares iterations (updates of \eqn{w} and \eqn{h})}

\item{threads}{number of CPU threads to use for parallelization. Default is "0" to let OpenMP decide and use all available threads.}

\item{verbose}{print tolerances for each iteration to the console}

\item{diag}{introduce a scaling diagonal by normalizing rows in \eqn{h} and columns in \eqn{w} to sum to 1, and sorting factors in the final model by decreasing diagonal values.}

\item{symmetric}{indicate whether \eqn{A} is a symmetric matrix, so \eqn{A} will not be transposed during alternating least squares and tolerance will measure correlation between \eqn{w} and \eqn{h} with each iteration rather than \eqn{h} between consecutive iterations. Diagonalization will also be applied to ensure convergence of \eqn{w} and \eqn{h}.}

\item{fast_maxit}{maximum number of iterations of pre-conditioning in NNLS solver prior to coordinate descent, see \code{\link{nnls}}}

\item{cd_maxit}{maximum number of iterations of coordinate descent NNLS solver, see \code{\link{nnls}}}

\item{cd_tol}{tolerance of NNLS coordinate descent solver, see \code{\link{nnls}}}

\item{calc_mse}{calculate mean squared error loss of the factorization at each iteration. This is computationally intensive.}

\item{precision}{"double" or "float", note that "float" will limit the tolerance of most models at convergence to around 1e-6.}
}
\value{
list of "w", "d", "h" giving matrices and diagonal vector of the learned factor model, and "tol", and "mse" giving the tolerances and loss (if calculated) of the model at each iteration
}
\description{
High-performance Non-Negative Matrix Factorization (NMF), one-sided NMF, or unconstrained matrix factorization with optional diagonalization and L1 regularization.
}
\details{
TBD
}
