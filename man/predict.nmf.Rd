% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/predict_nmf.r
\name{predict,nmf-method}
\alias{predict,nmf-method}
\alias{predict.nmf}
\title{Project an NMF model onto new samples}
\usage{
\S4method{predict}{nmf}(object, data, L1 = 0, L2 = 0, nonneg = TRUE, mask = NULL, ...)

predict.nmf(w, data, L1 = 0, L2 = 0, mask = NULL, ...)
}
\arguments{
\item{object}{fitted model, class \code{nmf}, generally the result of calling \code{nmf}, with models of equal dimensions as \code{data}}

\item{data}{dense or sparse matrix of features in rows and samples in columns. Prefer \code{matrix} or \code{Matrix::dgCMatrix}, respectively}

\item{L1}{a single LASSO penalty in the range (0, 1]}

\item{L2}{a single Ridge penalty greater than zero}

\item{nonneg}{enforce non-negativity}

\item{mask}{dense or sparse matrix of values in \code{data} to handle as missing. Prefer \code{Matrix::dgCMatrix}. Alternatively, specify "\code{zeros}" or "\code{NA}" to mask either all zeros or NA values.}

\item{...}{arguments passed to or from other methods}

\item{w}{matrix of features (rows) by factors (columns), corresponding to rows in \code{data}}
}
\value{
object of class \code{\link{nmf}}
}
\description{
Given an NMF model in the form \eqn{A = wdh}, \code{predict.nmf} projects \code{w} onto \code{A} to solve for \code{h}.
}
\details{
TO DO: add documentation
For the alternating least squares matrix factorization update problem \eqn{A = wh}, the updates 
(or projection) of \eqn{h} is given by the equation: \deqn{w^Twh = wA_j} 
which is in the form \eqn{ax = b} where \eqn{a = w^Tw} \eqn{x = h} and \eqn{b = wA_j} for all columns \eqn{j} in \eqn{A}.

Any L1 penalty is subtracted from \eqn{b} and should generally be scaled to \code{max(b)}, where \eqn{b = WA_j} for all columns \eqn{j} in \eqn{A}. An easy way to properly scale an L1 penalty is to normalize all columns in \eqn{w} to sum to the same value (e.g. 1). No scaling is applied in this function. Such scaling guarantees that \code{L1 = 1} gives a completely sparse solution.

There are specializations for dense and sparse input matrices, symmetric input matrices, and for rank-1 and rank-2 projections. See documentation for \code{\link{nmf}} for theoretical details and guidance.
}
\examples{
\dontrun{
TO DO
library(Matrix)
w <- matrix(runif(1000 * 10), 1000, 10)
h_true <- matrix(runif(10 * 100), 10, 100)
# A is the crossproduct of "w" and "h" with 10\% signal dropout
A <- (w \%*\% h_true) * (rsparsematrix(1000, 100, 0.9) > 0)
h <- project(A, w)
cor(as.vector(h_true), as.vector(h))

# alternating projections refine solution (like NMF)
mse_bad <- mse(A, w, rep(1, ncol(w)), h) # mse before alternating updates
h <- project(A, w = w)
w <- project(A, h = h)
h <- project(A, w)
w <- project(A, h = h)
h <- project(A, w)
w <- t(project(A, h = h))
mse_better <- mse(A, w, rep(1, ncol(w)), h) # mse after alternating updates
mse_better < mse_bad

# two ways to solve for "w" that give the same solution
w <- project(A, h = h)
w2 <- project(t(A), w = t(h))
all.equal(w, w2)
}
}
\references{
DeBruine, ZJ, Melcher, K, and Triche, TJ. (2021). "High-performance non-negative matrix factorization for large single-cell data." BioRXiv.
}
\seealso{
\code{\link{nnls}}, \code{\link{nmf}}
}
\author{
Zach DeBruine
}
